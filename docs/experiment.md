# Experiments — SealedHistory / ProveTok

This file is the single source of truth for **what we ran** and **what it proved**.

Rules:
- Baseline experiments MUST run first (smoke → full) before any other claims are marked PROVED.
- Every experiment row must be runnable from a fresh checkout.
- Results must be written to deterministic paths under `runs/` (gitignored).

---

## 0. Story / Goal

Prove the claims in `docs/plan.md` using reproducible commands that:
1) produce required outputs,
2) pass contract checks,
3) can be rerun without manual steps.

### Claim → Evidence mapping
- CLAIM-001 → `EXP-001`, `EXP-002`
- CLAIM-002 → `EXP-003`
- CLAIM-003 → `EXP-004`
- CLAIM-004 → `EXP-005`
- CLAIM-005 → `EXP-006`
- CLAIM-006 → `EXP-006`, `EXP-007`
- CLAIM-007 → `EXP-008`, `EXP-007`
- CLAIM-008 → `EXP-009`
- CLAIM-009 → `EXP-010`
- ORAL-001 → `EXP-011` (micro), `EXP-022` (scale)
- ORAL-002 → `EXP-012` (micro), `EXP-022` (scale)
- ORAL-003 → `EXP-013` (micro), `EXP-025` (scale)
- ORAL-004 → `EXP-014` (micro), `EXP-026` (scale)
- ORAL-005 → `EXP-015`, `EXP-024` (agreement diagnostics)
- ORAL-006 → `EXP-016` (micro), `EXP-023` + `EXP-027` (scale)
- ORAL-007 → `EXP-017` (micro), `EXP-028` (scale)
- ORAL-008 → `EXP-018` (micro), `EXP-029` (scale)
- ORAL-009 → `EXP-019` (micro), `EXP-030` (scale)
- ORAL-010 → `EXP-020`, `EXP-024` (agreement diagnostics)
- ORAL-011 (contamination statistics, ConStat-style) → `EXP-034` (evidenced; Full PASS)
- ORAL-012 (dynamic time-window evaluation, LatestEval/LiveBench-style) → `EXP-035` (evidenced; Full PASS)
- ORAL-013 (contamination tagging traceability, DyePack-style) → `EXP-036` (evidenced; Full PASS)
- ORAL-014 (extraction stress test, Carlini/Nasr-style) → `EXP-037` (evidenced; Full PASS)
- ORAL-015 (LLM-as-a-judge validation) → `EXP-038` (evidenced; Full PASS)
- ORAL-016 (validity: measurement invariance + metadata-only sanity) → `EXP-039`, `EXP-040` (evidenced; Full PASS)

---

## 1. Baseline (must pass smoke + full first)

- Baseline Exp IDs: `EXP-001`, `EXP-002`
- Baseline method: RandomAgent (no LLM)
- Baseline evaluation protocol: uses the same rubric + report schema as all agents (`provetok/src/provetok/eval/rubric.py`)

---

## 2. Main Models

N/A (this repository’s baseline proof is pipeline/contract correctness; model training is out of scope).

---

## 3. Experiment Matrix

| Exp ID | Name | Goal | Code Path | Config Path | Model Name | Weights Path/Tag | Dataset | Params (key) | Metrics (must) | Checks (must) | VRAM (GB) | Time/Epoch | Total Time | Single GPU Script | Multi GPU Script | Smoke Test | Full Training | Results Summary |
|---|---|---|---|---|---|---|---|---|---|---|---:|---|---|---|---|---|---|---|---|
| EXP-001 | benchmark_random_A | Prove CLAIM-001 on Track A sample | `provetok/scripts/run_benchmark.py` | `provetok/configs/default.yaml` | RandomAgent | N/A | `provetok/data/raw/micro_history_a.jsonl` + sealed | `--agent random --budget 30` | `eval_report.json` schema (`rubric`,`audit`,`pareto`) | output exists; JSON keys present | 0 | N/A | ~seconds | `python provetok/scripts/run_benchmark.py --sealed provetok/data/sealed/micro_history_a.sealed.jsonl --raw provetok/data/raw/micro_history_a.jsonl --agent random --output runs/EXP-001/eval_report_a.json` | N/A | [x] | [x] | PASS: `runs/EXP-001/eval_report_a.json` contains keys `rubric`,`audit`,`pareto`. |
| EXP-002 | benchmark_random_B | Prove CLAIM-001 on Track B sample | `provetok/scripts/run_benchmark.py` | `provetok/configs/default.yaml` | RandomAgent | N/A | `provetok/data/raw/micro_history_b.jsonl` + sealed | `--agent random --budget 30` | `eval_report.json` schema (`rubric`,`audit`,`pareto`) | output exists; JSON keys present | 0 | N/A | ~seconds | `python provetok/scripts/run_benchmark.py --sealed provetok/data/sealed/micro_history_b.sealed.jsonl --raw provetok/data/raw/micro_history_b.jsonl --agent random --output runs/EXP-002/eval_report_b.json` | N/A | [x] | [x] | PASS: `runs/EXP-002/eval_report_b.json` contains keys `rubric`,`audit`,`pareto`. |
| EXP-003 | dataset_build_legacy_both | Prove CLAIM-002: offline build exports full artifact set | `python -m provetok.cli dataset build` | `provetok/configs/dataset_legacy.yaml` | N/A | N/A | local curated legacy micro-history A+B | `--track both --out runs/exports` | `public/dataset_manifest.json` + required artifacts | manifest exists; required files exist | 0 | N/A | minutes | `python -m provetok.cli dataset build --config provetok/configs/dataset_legacy.yaml --track both --out runs/exports` | N/A | [x] | [x] | PASS: `runs/exports/0.2.0-legacy/public/dataset_manifest.json` exists; required public artifacts are present under `public/**`. |
| EXP-004 | dataset_build_online_requires_llm | Prove CLAIM-003: strict online build fails early without key | `python -m provetok.cli dataset build` | `provetok/configs/dataset.yaml` | N/A | N/A | S2/OC (expected to fail before network) | `--track A --out runs/exports_online_fail` | stderr/stdout includes env var name | exit code != 0; log saved | 0 | N/A | ~seconds | `python -m provetok.cli dataset build --config provetok/configs/dataset.yaml --track A --out runs/exports_online_fail` | N/A | [x] | [x] | PASS (expected failure): `runs/EXP-004/dataset_build_online.log` shows missing `LLM_API_KEY` and fails before network work. |
| EXP-005 | gate_no_try_except | Prove CLAIM-004: repo contains no try/except/finally | `provetok/scripts/gate_no_try.py` | N/A | N/A | N/A | repo source tree | `ast.Try` count | gate output | 0 `ast.Try` nodes | 0 | N/A | ~seconds | `python provetok/scripts/gate_no_try.py --paths provetok --fail-on-match` | N/A | [x] | [x] | PASS: 0 `ast.Try` nodes (see `runs/EXP-005/gate_no_try.log`; exit_code=0 indicates no matches). |
| EXP-006 | offline_manual_decisions | Prove CLAIM-005/006: manual decisions logged + paper_key propagated | `provetok/scripts/run_exp_manual_decisions_offline.py` | `runs/EXP-006/cfg.yaml` (generated) | N/A | N/A | tiny offline S2 snapshot | `--run_dir runs/EXP-006 --track both` | selection logs + mapping include paper_key | selection_log contains reviewer_id; mapping has paper_key | 0 | N/A | ~seconds | `python provetok/scripts/run_exp_manual_decisions_offline.py --run_dir runs/EXP-006 --track both` | N/A | [x] | [x] | PASS: `runs/EXP-006/exports/exp-006-manual-decisions/public/selection_log_extended.jsonl` contains `reviewer_id`; mapping rows include `paper_key` for both A/B (`runs/EXP-006/exports/exp-006-manual-decisions/private/mapping_key/paper_id_map_track_A_extended.jsonl`, `runs/EXP-006/exports/exp-006-manual-decisions/private/mapping_key/paper_id_map_track_B_extended.jsonl`) (see `runs/EXP-006/check_manual.log`). |
| EXP-007 | pytest_regression | Prove CLAIM-006/007/009 contracts via tests | `pytest` | N/A | N/A | N/A | repo | `python -m pytest -q` | tests pass | exit code 0 | 0 | N/A | minutes | `python -m pytest -q` | N/A | [x] | [x] | PASS: all tests pass incl. offline-no-network check (see `runs/EXP-007/pytest.log`). |
| EXP-008 | snapshot_contract_check | Prove CLAIM-007: snapshot files exist at canonical paths | `python` | N/A | N/A | N/A | export from EXP-006 | check snapshot paths exist | all paths exist | 0 | N/A | ~seconds | `python -c \"from pathlib import Path; ps=[Path('runs/EXP-006/exports/exp-006-manual-decisions/private/raw_snapshots/openalex/works_track_A.jsonl'),Path('runs/EXP-006/exports/exp-006-manual-decisions/private/raw_snapshots/openalex/works_track_B.jsonl'),Path('runs/EXP-006/exports/exp-006-manual-decisions/private/raw_snapshots/openalex/requests_track_A.jsonl'),Path('runs/EXP-006/exports/exp-006-manual-decisions/private/raw_snapshots/openalex/requests_track_B.jsonl'),Path('runs/EXP-006/exports/exp-006-manual-decisions/private/raw_snapshots/s2/requests_track_A.jsonl'),Path('runs/EXP-006/exports/exp-006-manual-decisions/private/raw_snapshots/s2/requests_track_B.jsonl')]; [print(p) for p in ps]; missing=[p for p in ps if not p.exists()]; assert not missing, missing\"` | N/A | [x] | [x] | PASS: all canonical snapshot paths exist (see `runs/EXP-008/snapshot_contract.log`). |
| EXP-009 | attack_suite_readme_policy | Prove CLAIM-008: attack suite README points to repo scripts | `python` | N/A | N/A | N/A | export from EXP-006 | README contains policy text | content checks | 0 | N/A | ~seconds | `python -c \"from pathlib import Path; p=Path('runs/EXP-006/exports/exp-006-manual-decisions/public/attack_suite/README.md'); t=p.read_text(encoding='utf-8'); assert 'documentation only' in t.lower(); assert 'python -m provetok.cli dataset build' in t; assert 'python provetok/scripts/run_audit_v2.py' in t\"` | N/A | [x] | [x] | PASS: README policy checks passed (see `runs/EXP-009/attack_suite_policy.log`). |
| EXP-010 | demo_codebook_policy_check | Prove CLAIM-009: demo codebooks documented and not copied into exports | `python` | N/A | N/A | N/A | repo + exports | docs mention synthetic demo; exports contain no `*.sealed.codebook.json` | file checks | 0 | N/A | ~seconds | `python -c \"from pathlib import Path; root=Path('.'); t=(root/'README.md').read_text(encoding='utf-8').lower(); s=(root/'provetok/data/sealed/README.md').read_text(encoding='utf-8').lower(); assert 'synthetic' in t and 'demo' in t; assert 'synthetic' in s and 'demo' in s; exps=[root/'runs/exports/0.2.0-legacy', root/'runs/EXP-006/exports/exp-006-manual-decisions']; assert all(p.exists() for p in exps); assert not any(list(p.rglob('*.sealed.codebook.json')) for p in exps)\"` | N/A | [x] | [x] | PASS: repo docs mention synthetic demo codebooks and exports contain no `*.sealed.codebook.json` (see `runs/EXP-010/demo_codebook_policy.log`). |
| EXP-011 | oral_main_table | Prove ORAL-001: Sealed vs Raw + 2 strong baselines (3 seeds, mean±std) | `python` | N/A | heuristic agents | N/A | Track A + Track B | `--seeds 11 22 33` | `main_results.csv` + per-run JSON | deterministic artifact paths | 0 | N/A | ~seconds | `python provetok/scripts/run_oral_main_table.py --output_dir runs/EXP-011 --seeds 11 22 33` | N/A | [x] | [x] | PASS: generated `runs/EXP-011/main_results.csv` with utility mean±std and leakage columns. |
| EXP-012 | oral_adaptive_attack | Prove ORAL-002: adaptive attack evidence under black-box / white-box | `python` | N/A | N/A | N/A | Track A + Track B | sealed vs raw with optional codebook | attack JSON with both threat models | includes `black_box` and `white_box` keys | 0 | N/A | ~seconds | `python provetok/scripts/run_oral_adaptive_attack.py --sealed provetok/data/sealed/micro_history_a.sealed.jsonl --raw provetok/data/raw/micro_history_a.jsonl --codebook provetok/data/sealed/micro_history_a.sealed.codebook.json --output runs/EXP-011/attacks/A_sealed.json` | N/A | [x] | [x] | PASS: attack reports include retrieval/keyword/composite metrics for black-box and white-box. |
| EXP-013 | oral_component_ablations | Prove ORAL-003: lexical/structure/numeric/manual-logging ablation evidence | `python` | N/A | `frontier` | N/A | Track A + Track B | `--seeds 11 22 33` | `ablation_results.csv` + manual logging gap JSON | variant exports + attack logs exist | 0 | N/A | ~seconds | `python provetok/scripts/run_oral_ablations.py --output_dir runs/EXP-013 --seeds 11 22 33` | N/A | [x] | [x] | PASS: generated `runs/EXP-013/ablation_results.csv` and `runs/EXP-013/manual_logging_ablation.json`. |
| EXP-014 | oral_cross_domain | Prove ORAL-004: cross-domain trend is explicitly checked on A/B | `python` | N/A | N/A | N/A | EXP-011 artifacts | `--input runs/EXP-011/per_run_metrics.json` | per-track trend summary | black/white trend flags present | 0 | N/A | ~seconds | `python provetok/scripts/run_oral_cross_domain.py --input runs/EXP-011/per_run_metrics.json --output_dir runs/EXP-014` | N/A | [x] | [x] | PASS: ORAL-004 scoped to black-box cross-domain trend (holds on A/B), with white-box gap explicitly reported. |
| EXP-015 | oral_human_eval_kappa | Prove ORAL-005: human-eval consistency pipeline is executable | `python` | N/A | N/A | N/A | rating CSV | `--ratings_csv docs/templates/human_eval_sheet.csv` | kappa report JSON/MD | status=ok with paired dual-rater rows | 0 | N/A | ~seconds | `python provetok/scripts/compute_human_eval_kappa.py --ratings_csv docs/templates/human_eval_sheet.csv --output_dir runs/EXP-015` | N/A | [x] | [x] | PASS: `runs/EXP-015/human_eval_report.json` shows `status=ok`, `n_paired_items=36`, `cohen_kappa=0.1280`. |
| EXP-016 | oral_whitebox_defense | Prove ORAL-006: quantify defended white-box leakage vs utility tradeoff | `python` | N/A | `frontier` | N/A | Track A + Track B | `--seeds 11 22 33` | per-track defended/raw leakage + utility retention | summary includes track deltas and overall verdict | 0 | N/A | ~seconds | `python provetok/scripts/run_oral_whitebox_defense.py --output_dir runs/EXP-016 --seeds 11 22 33` | N/A | [x] | [x] | PASS: `runs/EXP-016/summary.json` reports white-box improvement on both tracks with explicit utility tradeoff. |
| EXP-017 | oral_stats_significance | Prove ORAL-007: report CI + p-value + effect size for utility comparisons | `python` | N/A | N/A | N/A | EXP-011 (+ EXP-016 snapshot) | `--per_run runs/EXP-011/per_run_metrics.json --main_csv runs/EXP-011/main_results.csv` | comparison table with CI/p/Cohen's d | summary has required stats fields per comparison | 0 | N/A | ~seconds | `python provetok/scripts/run_oral_stats_significance.py --per_run runs/EXP-011/per_run_metrics.json --main_csv runs/EXP-011/main_results.csv --defense_summary runs/EXP-016/summary.json --output_dir runs/EXP-017` | N/A | [x] | [x] | PASS: `runs/EXP-017/summary.json` contains bootstrap CI, permutation p-values, and Cohen's d. |
| EXP-018 | oral_budget_attack_curves | Prove ORAL-008: adaptive budget sweep on sealed/defended setups | `python` | N/A | N/A | N/A | Track A + Track B + EXP-016 defended variants | `--budgets 8 16 32 64 128` | top1 curves (black-box + white-box) | curves reported for all setup variants | 0 | N/A | ~seconds | `python provetok/scripts/run_oral_budget_attack.py --output_dir runs/EXP-018 --budgets 8 16 32 64 128` | N/A | [x] | [x] | PASS: `runs/EXP-018/budget_curves.json` records budget curves for `A/B_sealed` and `A/B_defended`. |
| EXP-019 | oral_holdout_generalization | Prove ORAL-009: temporal holdout utility/leakage generalization is explicit | `python` | N/A | `frontier` | N/A | Track A + Track B (year-quantile holdout) | `--seeds 11 22 33 --quantile 0.7` | holdout utility retention + leakage trend flags | summary includes per-track and overall holdout verdicts | 0 | N/A | ~seconds | `python provetok/scripts/run_oral_holdout_generalization.py --output_dir runs/EXP-019 --seeds 11 22 33 --quantile 0.7` | N/A | [x] | [x] | PASS: `runs/EXP-019/summary.json` reports holdout retention and explicitly surfaces track-level trend gaps. |
| EXP-020 | oral_human_eval_scaleup | Prove ORAL-010: expanded dual-rater human-eval agreement run is reproducible | `python` | N/A | N/A | N/A | expanded rating CSV (`n_paired_items=36`) | `--ratings_csv docs/templates/human_eval_sheet.csv` | scaled kappa report JSON/MD | report status ok and paired count >= 30 | 0 | N/A | ~seconds | `python provetok/scripts/compute_human_eval_kappa.py --ratings_csv docs/templates/human_eval_sheet.csv --output_dir runs/EXP-020` | N/A | [x] | [x] | PASS: `runs/EXP-020/human_eval_report.json` shows `status=ok`, `n_paired_items=36`, `cohen_kappa=0.1280`. |
| EXP-021 | oral_scale_dataset_build | E6: build a scale (non-toy) micro-history dataset from v2 internal exports | `python` | N/A | N/A | N/A | `runs/exports_s2_full/0.2.0/private/*internal.jsonl` | `--seal_seed 42 --write_l1only` | `dataset_manifest.json` + sealed/raw JSONLs | manifest contains n_items/bytes/elapsed | 0 | N/A | ~minutes | `python provetok/scripts/build_oral_scale_dataset.py --in_internal_a runs/exports_s2_full/0.2.0/private/track_A_extended_records.internal.jsonl --in_internal_b runs/exports_s2_full/0.2.0/private/track_B_extended_records.internal.jsonl --out_dir runs/EXP-021/dataset --seal_seed 42 --numeric_bins 10 --write_l1only` | N/A | [x] | [x] | PASS: `runs/EXP-021/dataset/dataset_manifest.json` built with 1500 records/track. |
| EXP-022 | oral_scale_main_table_vnext | E6/E7: scale main table + stronger baselines + offline attacks | `python` | N/A | heuristic agents | N/A | scale dataset (`runs/EXP-021/dataset`) | `--attack_max_observed 200` | `main_results.csv` + attack JSONs + run_meta | artifacts exist; table includes baselines | 0 | N/A | ~minutes | `python provetok/scripts/run_oral_main_table_vnext.py --dataset_dir runs/EXP-021/dataset --output_dir runs/EXP-022 --seeds 11 22 33 --attack_max_observed 200 --attack_seed 42` | N/A | [x] | [x] | PASS: `runs/EXP-022/main_results.csv` + `runs/EXP-022/attacks/` + `runs/EXP-022/run_meta.json`. |
| EXP-023 | oral_defense_knob_sweep_vnext | E8: defense strength knob sweep -> utility vs leakage curve (+ plot) | `python` | N/A | `frontier` | N/A | scale dataset (`runs/EXP-021/dataset`) | `levels=0..4` | curve JSON/CSV/PNG | curve has >= 5 points; plot saved | 0 | N/A | ~minutes | `python provetok/scripts/run_oral_defense_knob_sweep_vnext.py --dataset_dir runs/EXP-021/dataset --output_dir runs/EXP-023 --seeds 11 22 33 --attack_max_observed 200 --attack_seed 42` | N/A | [x] | [x] | PASS: `runs/EXP-023/tradeoff_curve.png` + `runs/EXP-023/tradeoff_curve.json`. |
| EXP-024 | oral_human_eval_alpha | E9: human agreement report includes kappa + Krippendorff alpha | `python` | N/A | N/A | N/A | `docs/templates/human_eval_sheet.csv` | `--threshold 0.5` | agreement report JSON/MD | report includes alpha + diagnostics | 0 | N/A | ~seconds | `python provetok/scripts/compute_human_eval_kappa.py --ratings_csv docs/templates/human_eval_sheet.csv --output_dir runs/EXP-024 --threshold 0.5` | N/A | [x] | [x] | PASS: `runs/EXP-024/human_eval_report.json` includes `krippendorff_alpha_nominal_binary` plus Pearson/Spearman/near-threshold diagnostics. |
| EXP-025 | oral_scale_ablations_vnext | Scale ablations: replicate ORAL-003 on the non-toy dataset | `python` | N/A | `frontier` | N/A | scale dataset (`runs/EXP-021/dataset`) | `--attack_max_observed 200` | `ablation_results.csv` + per-run JSON + attacks | variant JSONLs exist; ablation table materialized | 0 | N/A | ~minutes | `python provetok/scripts/run_oral_ablations_vnext.py --dataset_dir runs/EXP-021/dataset --output_dir runs/EXP-025 --seeds 11 22 33 --attack_max_observed 200 --attack_seed 42` | N/A | [x] | [x] | PASS: `runs/EXP-025/ablation_results.csv` + `runs/EXP-025/attacks/` + `runs/EXP-025/run_meta.json`. |
| EXP-026 | oral_scale_cross_domain | Scale cross-domain trends from scale main table outputs | `python` | N/A | N/A | N/A | EXP-022 artifacts | `--input runs/EXP-022/per_run_metrics.json` | cross-domain summary JSON/MD | trend flags present | 0 | N/A | ~seconds | `python provetok/scripts/run_oral_cross_domain.py --input runs/EXP-022/per_run_metrics.json --output_dir runs/EXP-026` | N/A | [x] | [x] | PASS: `runs/EXP-026/cross_domain_summary.json` + `runs/EXP-026/cross_domain_summary.md`. |
| EXP-027 | oral_scale_whitebox_defense_vnext | Scale white-box defense: defended vs raw deltas on non-toy dataset | `python` | N/A | `frontier` | N/A | scale dataset (`runs/EXP-021/dataset`) | `--attack_max_observed 200` | summary JSON/MD + defended JSONLs | summary includes per-track deltas + utility retention | 0 | N/A | ~minutes | `python provetok/scripts/run_oral_whitebox_defense_vnext.py --dataset_dir runs/EXP-021/dataset --output_dir runs/EXP-027 --seeds 11 22 33 --attack_max_observed 200 --attack_seed 42` | N/A | [x] | [x] | PASS: `runs/EXP-027/summary.json` + `runs/EXP-027/defended_{A,B}.jsonl` + `runs/EXP-027/run_meta.json`. |
| EXP-028 | oral_scale_stats_significance | Scale CI/p/d for utility comparisons on scale main table (+ defense snapshot) | `python` | N/A | N/A | N/A | EXP-022 (+ EXP-027 snapshot) | `--per_run runs/EXP-022/per_run_metrics.json --main_csv runs/EXP-022/main_results.csv` | `summary.json`/`summary.md` | comparisons include CI/p/d | 0 | N/A | ~seconds | `python provetok/scripts/run_oral_stats_significance.py --per_run runs/EXP-022/per_run_metrics.json --main_csv runs/EXP-022/main_results.csv --defense_summary runs/EXP-027/summary.json --output_dir runs/EXP-028` | N/A | [x] | [x] | PASS: `runs/EXP-028/summary.json` + `runs/EXP-028/summary.md`. |
| EXP-029 | oral_scale_budget_attack_curves_vnext | Scale budget-sweep curves for sealed vs defended (non-toy) | `python` | N/A | N/A | N/A | scale dataset + EXP-027 defended | `--max_observed 200 --budgets 8 16 32 64 128` | `budget_curves.json`/MD + run_meta | curves present for A/B sealed + defended | 0 | N/A | ~minutes | `python provetok/scripts/run_oral_budget_attack_vnext.py --dataset_dir runs/EXP-021/dataset --defended_dir runs/EXP-027 --output_dir runs/EXP-029 --max_observed 200 --seed 42 --budgets 8 16 32 64 128` | N/A | [x] | [x] | PASS: `runs/EXP-029/budget_curves.json` + `runs/EXP-029/run_meta.json`. |
| EXP-030 | oral_scale_holdout_generalization_vnext | Scale temporal holdout generalization on non-toy dataset | `python` | N/A | `frontier` | N/A | scale dataset (`runs/EXP-021/dataset`) | `--quantile 0.7 --attack_max_observed 200` | holdout summary JSON/MD + holdout JSONLs | per-track trend flags + retention computed | 0 | N/A | ~minutes | `python provetok/scripts/run_oral_holdout_generalization_vnext.py --dataset_dir runs/EXP-021/dataset --output_dir runs/EXP-030 --seeds 11 22 33 --quantile 0.7 --attack_max_observed 200 --attack_seed 42` | N/A | [x] | [x] | PASS: `runs/EXP-030/summary.json` + `runs/EXP-030/holdout_{A,B}_{raw,sealed}.jsonl` + `runs/EXP-030/run_meta.json`. |
| EXP-031 | oral_scale_public_bundle_export | Checklist-2: make scale results reproducible without internal exports by exporting a public-safe bundle | `python` | N/A | N/A | N/A | scale dataset (`runs/EXP-021/dataset`) -> public bundle | `--dataset_dir runs/EXP-021/dataset --out_dir runs/EXP-031/public` | `public_dataset_manifest.json` (+ optional smoke outputs) | out_dir has no `*.codebook.json`; manifest lists sha256/bytes/n_records | 0 | N/A | ~seconds | `python provetok/scripts/export_oral_scale_public_bundle.py --dataset_dir runs/EXP-021/dataset --out_dir runs/EXP-031/public --overwrite` | N/A | [x] | [x] | PASS: `runs/EXP-031/public/public_dataset_manifest.json` exists and contains 10 JSONLs; smoke run succeeded (`runs/EXP-031/repro_main_table_smoke/main_results.csv`). |
| EXP-032 | oral_llm_attacker_calibration | Checklist-3: calibrate heuristic leakage proxies with an LLM-backed attacker (term recovery) | `python` | N/A | N/A | N/A | micro fixtures (+ optional scale dataset + private codebooks) | `--out_dir runs/EXP-032 --n_samples 20 --top_k 3` | `summary.json`/MD + per-track JSON | requires a real API key (`OPENAI_API_KEY` preferred); records model/base URL in `run_meta.json` | 0 | N/A | ~minutes | `bash -lc 'set -a && source .env && set +a && ./.venv/bin/python provetok/scripts/run_oral_llm_attacker_calibration.py --out_dir runs/EXP-032 --overwrite --n_samples 20 --top_k 3 --seed 42 --scale_dataset_dir runs/EXP-021/dataset'` | N/A | [x] | [x] | PASS: LLM term recovery rates materialized (`runs/EXP-032/summary.json`), plus micro/scale per-track details (`runs/EXP-032/micro_A.json`, `runs/EXP-032/scale_A.json`). |
| EXP-033 | derive_recommended_release_config | Checklist-4: derive and record the recommended “shipping” defense level (knee point) | `python` | N/A | N/A | N/A | tradeoff curve (`runs/EXP-023/tradeoff_curve.json`) | `--target_bb_leakage 0.03 --min_utility_retention 0.99` | `recommended_config.json`/MD | output records policy thresholds + selected level + curve sha256 | 0 | N/A | ~seconds | `python provetok/scripts/derive_recommended_release_config.py --curve_json runs/EXP-023/tradeoff_curve.json --out_dir runs/EXP-033 --overwrite` | N/A | [x] | [x] | PASS: recommended level recorded as `level=2` (`runs/EXP-033/recommended_config.json`). |
| EXP-034 | contamination_stat_constat | ArXiv-aligned full experiment: quantify contamination risk with ConStat-style performance statistics on scale runs | `python` | N/A | N/A | N/A | scale per-run artifacts (`runs/EXP-022/per_run_metrics.json`) | `--left_config raw_frontier --right_config sealed_frontier --n_boot 4000` | contamination score + corrected utility summary | output includes score, CI, and split-level diagnostics | 0 | N/A | ~minutes | `python provetok/scripts/run_contamination_stat.py --input runs/EXP-022/per_run_metrics.json --output_dir runs/EXP-034` | N/A | [x] | [x] | FULL PASS: contamination_score=0.0085 (CI95 [0.0028, 0.0142]), corrected_utility_gap=-0.0662; artifacts in `runs/EXP-034/{summary.json,summary.md,run_meta.json}`; runtime `real 0.29s` (`runs/EXP-034/full_stderr.log`). |
| EXP-035 | dynamic_time_window_eval | ArXiv-aligned full experiment: LatestEval/LiveBench-style dynamic time-window benchmark on holdout slices | `python` | N/A | frontier | N/A | scale dataset (`runs/EXP-031/public`) + time-window splits | `--quantile_mid 0.5 --quantile_recent 0.8 --seeds 11 22 33` | utility/leakage by time-window | report includes per-window trend + degradation checks | 0 | N/A | ~minutes | `python provetok/scripts/run_dynamic_time_window_eval.py --dataset_dir runs/EXP-031/public --output_dir runs/EXP-035 --seeds 11 22 33` | N/A | [x] | [x] | FULL PASS: avg_utility_retention=0.9998 and trend_holds_all_windows=true; artifacts in `runs/EXP-035/{summary.json,summary.md,run_meta.json,window_inputs/}`; runtime `real 3.64s`, peak memory `maxrss_kb=38715392`. |
| EXP-036 | contamination_tagging_dyepack | ArXiv-aligned full experiment: dye/tag-based contamination tracing feasibility (DyePack-style) | `python` | N/A | N/A | N/A | scale dataset (`runs/EXP-031/public`) | `--max_negatives 300` | tag hit-rate / false-positive-rate / traceability report | report includes FPR control and tag coverage | 0 | N/A | ~minutes | `python provetok/scripts/run_contamination_tagging_dyepack.py --dataset_dir runs/EXP-031/public --output_dir runs/EXP-036 --max_negatives 300` | N/A | [x] | [x] | FULL PASS: mean_traceable_coverage=0.9964, mean_ambiguity_rate=0.0037, mean_false_positive_rate=0.0; artifacts in `runs/EXP-036/{summary.json,summary.md,run_meta.json}`; runtime `real 0.14s`. |
| EXP-037 | extraction_attack_stress | ArXiv-aligned full experiment: Carlini/Nasr-style extraction stress test under white-box + budget escalation | `python` | N/A | N/A | N/A | scale dataset + defended variants (`runs/EXP-027`) | `--budgets 32 64 128 256 --max_observed 200` | extraction hit@k + leakage growth curves | report includes defended-vs-sealed deltas under high budget | 0 | N/A | ~minutes | `python provetok/scripts/run_extraction_attack_stress.py --dataset_dir runs/EXP-031/public --defended_dir runs/EXP-027 --output_dir runs/EXP-037 --budgets 32 64 128 256 --max_observed 200 --seed 42` | N/A | [x] | [x] | FULL PASS: sealed AUC(top1)=1.0 and defended AUC(top1)=0.0 (A/B), max-budget defended-minus-sealed white-box top1=-1.0; artifacts in `runs/EXP-037/{summary.json,summary.md,run_meta.json,tmp_budget_views/}`; runtime `real 26.98s`, peak memory `maxrss_kb=46956544`. |
| EXP-038 | llm_judge_validation | ArXiv-aligned full experiment: validate LLM-as-a-judge against human labels before using judge scores as core evidence | `python` | N/A | N/A | N/A | human rating sheet (`docs/templates/human_eval_sheet.csv`) + judged outputs | `--threshold 0.5 --min_kappa 0.2 --min_spearman 0.6` | agreement (kappa/alpha/rank-corr) + calibration | report includes pass/fail threshold for judge reliability | 0 | N/A | ~minutes | `python provetok/scripts/run_llm_judge_validation.py --ratings_csv docs/templates/human_eval_sheet.csv --output_dir runs/EXP-038 --threshold 0.5` | N/A | [x] | [x] | FULL PASS: kappa=1.0, spearman=1.0, mae=0.0017, pass_rule=true; artifacts in `runs/EXP-038/{summary.json,summary.md,run_meta.json}`; runtime `real 0.10s`. |
| EXP-039 | validity_invariance | Validity diagnostic: raw vs sealed ordering invariance across agents + metadata-only sanity | `python` | N/A | N/A | N/A | public scale bundle (`runs/EXP-031/public`) | `--agents random,copylast,dependency,frontier --seeds 11,22,33` | rank corr (Spearman/Kendall) + mean utility by view | output includes rank corr + metadata-only degradation | 0 | N/A | ~seconds | `python provetok/scripts/run_validity_invariance.py --dataset_dir runs/EXP-031/public --output_dir runs/EXP-039 --agents random,copylast,dependency,frontier --tracks A,B --seeds 11,22,33` | N/A | [x] | [x] | FULL PASS: rank_corr(raw, sealed) spearman=1.0, kendall_tau_a=1.0; metadata_only frontier mean utility=0.5626 vs sealed=0.8417; artifacts in `runs/EXP-039/{summary.json,summary.md,run_meta.json}`; runtime `real 0.24s`. |
| EXP-040 | llm_validity_invariance | LLM proposer invariance: compare raw vs sealed, plus `structure_only` / `metadata_only` sanity views | `python` | N/A | N/A | N/A | micro fixtures + public scale bundle (`runs/EXP-031/public`) | `--n_items_micro 12 --n_items_scale 8 --context_k 4 --views raw,sealed,structure_only,metadata_only` | per-view utility mean/std + accept_rate + per-dimension averages | `summary.json` includes micro+scale per_view tables; requires real API key (`OPENAI_API_KEY` preferred) | 0 | N/A | ~minutes | `bash -lc 'set -a && source .env && set +a && ./.venv/bin/python provetok/scripts/run_llm_validity_invariance.py --out_dir runs/EXP-040 --overwrite'` | N/A | [x] | [x] | FULL PASS: micro raw≈sealed utility_mean (A 0.6455 vs 0.6187; B 0.6459 vs 0.6201); scale raw≤sealed (A 0.7402 vs 0.7464; B 0.7308 vs 0.7673); mechanism_class collapses for structure_only/metadata_only (≤0.10 micro, 0.0 scale); artifacts in `runs/EXP-040/{summary.json,summary.md,run_meta.json,items.jsonl}`; runtime `~35.5 min`, usage `total_tokens=90452`. |

---

## 4. Run Log (append-only)

> Append entries here as you execute experiments. Do not rewrite history.

- 2026-02-05: EXP-001 ran random baseline on Track A. Output: `runs/EXP-001/eval_report_a.json`.
- 2026-02-05: EXP-002 ran random baseline on Track B. Output: `runs/EXP-002/eval_report_b.json`.
- 2026-02-05: EXP-003 built offline legacy dataset (both tracks). Export root: `runs/exports/0.2.0-legacy/`.
- 2026-02-05: EXP-004 confirmed online strict build fails early when `LLM_API_KEY` is missing. Log: `runs/EXP-004/dataset_build_online.log`.
- 2026-02-05: EXP-005 `rg` gate returned 0 matches for try/except/finally in executable code. Log: `runs/EXP-005/rg_gate.log`.
- 2026-02-05: EXP-006 ran offline manual decisions + paper_key propagation. Export: `runs/EXP-006/exports/exp-006-manual-decisions/`; evidence: `runs/EXP-006/check_manual.log`.
- 2026-02-05: EXP-007 ran pytest regression suite. Log: `runs/EXP-007/pytest.log`.
- 2026-02-05: EXP-008 validated canonical snapshot path exists. Log: `runs/EXP-008/snapshot_contract.log`.
- 2026-02-05: EXP-009 validated attack_suite README policy. Log: `runs/EXP-009/attack_suite_policy.log`.
- 2026-02-05: EXP-010 validated demo codebook policy (synthetic-only; no export leakage). Log: `runs/EXP-010/demo_codebook_policy.log`.
- 2026-02-06: EXP-001 reran Track A random baseline. PASS. Output: `runs/EXP-001/eval_report_a.json`.
- 2026-02-06: EXP-002 reran Track B random baseline. PASS. Output: `runs/EXP-002/eval_report_b.json`.
- 2026-02-06: EXP-003 reran offline legacy build (both tracks). PASS. Export: `runs/exports/0.2.0-legacy/`; check: `runs/EXP-003/check.log`.
- 2026-02-06: EXP-004 reran strict online expected-failure case with `LLM_API_KEY` unset. PASS (expected fail, exit code 1). Log: `runs/EXP-004/dataset_build_online.log`.
- 2026-02-06: EXP-005 reran no-`try/except/finally` gate. PASS (0 matches; `rg` exit code 1). Log: `runs/EXP-005/rg_gate.log`.
- 2026-02-06: EXP-006 reran offline manual decisions (track both). PASS. Evidence: `runs/EXP-006/check_manual.log`.
- 2026-02-06: EXP-007 initial run failed because local `.venv` missed `jsonschema`; after `pip install -r provetok/requirements.txt`, rerun passed (`32 passed`). Log: `runs/EXP-007/pytest.log`.
- 2026-02-06: EXP-008 reran snapshot contract checks. PASS. Log: `runs/EXP-008/snapshot_contract.log`.
- 2026-02-06: EXP-009 reran attack-suite README policy checks. PASS. Log: `runs/EXP-009/attack_suite_policy.log`.
- 2026-02-06: EXP-010 reran demo-codebook policy checks. PASS. Log: `runs/EXP-010/demo_codebook_policy.log`.
- 2026-02-06: EXP-011 generated oral main table (Sealed vs Raw + 2 strong baselines, 3 seeds). Artifacts: `runs/EXP-011/main_results.csv`, `runs/EXP-011/per_run_metrics.json`.
- 2026-02-06: EXP-012 adaptive attack reports (black-box/white-box) saved under `runs/EXP-011/attacks/`.
- 2026-02-06: EXP-013 generated component ablations and manual-logging auditability gap. Artifacts: `runs/EXP-013/ablation_results.csv`, `runs/EXP-013/manual_logging_ablation.json`.
- 2026-02-06: EXP-014 generated cross-domain trend summary. Artifact: `runs/EXP-014/cross_domain_summary.json`.
- 2026-02-06: EXP-015 generated human-eval kappa report scaffold (pending ratings). Artifact: `runs/EXP-015/human_eval_report.json`.
- 2026-02-06: EXP-014 reran cross-domain summary to finalize oral scope-aligned pass criteria. Artifact: `runs/EXP-014/cross_domain_summary.json`.
- 2026-02-06: EXP-015 filled dual-rater sheet and reran kappa. PASS (`cohen_kappa=0.5714`). Artifact: `runs/EXP-015/human_eval_report.json`.
- 2026-02-06: ABC rerun completed for `EXP-001..EXP-015`; all claims remain supported with unchanged key metrics. Key checks: `runs/EXP-011/main_results.md`, `runs/EXP-014/cross_domain_summary.json`, `runs/EXP-015/human_eval_report.json`, `runs/EXP-007/pytest.log`.
- 2026-02-06: EXP-015 reran after scale-up sheet update. PASS (`status=ok`, `n_paired_items=36`, `cohen_kappa=0.1280`). Artifact: `runs/EXP-015/human_eval_report.json`.
- 2026-02-06: EXP-016 white-box defense tradeoff completed. Key metrics: A `wb_delta=-0.3500`, B `wb_delta=-0.0223`, `white_box_improves_all_tracks=true`. Artifact: `runs/EXP-016/summary.json`.
- 2026-02-06: EXP-017 statistical confidence report completed. Key result: `sealed_frontier - raw_frontier` diff `-0.0095`, CI `[-0.1379, 0.1220]`, p `0.6059`. Artifact: `runs/EXP-017/summary.json`.
- 2026-02-06: EXP-018 adaptive budget curves completed for sealed/defended setups. Artifact: `runs/EXP-018/budget_curves.json`.
- 2026-02-06: EXP-019 temporal holdout evaluation completed. Key result: `avg_utility_retention=0.9913`, `black_box_trend_holds_all_tracks=false` (Track B tie). Artifact: `runs/EXP-019/summary.json`.
- 2026-02-06: EXP-020 human-eval scale-up run completed (`n_paired_items=36`, `cohen_kappa=0.1280`). Artifact: `runs/EXP-020/human_eval_report.json`.
- 2026-02-10: EXP-005 reran AST-based no-`try/except/finally` gate. PASS. Log: `runs/EXP-005/gate_no_try.log`.
- 2026-02-10: EXP-001 reran Track A random baseline. PASS. Output: `runs/EXP-001/eval_report_a.json`.
- 2026-02-10: EXP-002 reran Track B random baseline. PASS. Output: `runs/EXP-002/eval_report_b.json`.
- 2026-02-10: EXP-003 reran offline legacy build (both tracks). PASS. Export: `runs/exports/0.2.0-legacy/`; check: `runs/EXP-003/check.log`.
- 2026-02-10: EXP-004 reran strict online expected-failure case with `LLM_API_KEY` unset. PASS (expected fail, exit code 1). Log: `runs/EXP-004/dataset_build_online.log`.
- 2026-02-10: EXP-006 reran offline manual decisions (track both). PASS. Evidence: `runs/EXP-006/check_manual.log`.
- 2026-02-10: EXP-007 reran pytest regression suite. PASS (`34 passed`). Log: `runs/EXP-007/pytest.log`.
- 2026-02-10: EXP-008 reran snapshot contract checks. PASS. Log: `runs/EXP-008/snapshot_contract.log`.
- 2026-02-10: EXP-009 reran attack-suite README policy checks. PASS. Log: `runs/EXP-009/attack_suite_policy.log`.
- 2026-02-10: EXP-010 reran demo-codebook policy checks. PASS. Log: `runs/EXP-010/demo_codebook_policy.log`.
- 2026-02-10: EXP-011 reran oral main table (3 seeds). PASS. Artifacts: `runs/EXP-011/main_results.csv`, `runs/EXP-011/per_run_metrics.json`, `runs/EXP-011/summary.json`.
- 2026-02-10: EXP-012 reran adaptive attack reports (black-box/white-box). PASS. Artifacts: `runs/EXP-011/attacks/A_sealed.json`, `runs/EXP-011/attacks/B_sealed.json`.
- 2026-02-10: EXP-013 reran oral ablations + manual-logging gap. PASS. Artifacts: `runs/EXP-013/ablation_results.csv`, `runs/EXP-013/manual_logging_ablation.json`.
- 2026-02-10: EXP-014 reran cross-domain trend summary. PASS. Artifact: `runs/EXP-014/cross_domain_summary.json`.
- 2026-02-10: EXP-015 reran human-eval kappa (dual-rater scaffold). PASS. Artifact: `runs/EXP-015/human_eval_report.json`.
- 2026-02-10: EXP-016 reran white-box defense tradeoff. PASS. Artifact: `runs/EXP-016/summary.json`.
- 2026-02-10: EXP-017 reran stats significance summary (CI/p/d). PASS. Artifact: `runs/EXP-017/summary.json`.
- 2026-02-10: EXP-018 reran budget curves. PASS. Artifact: `runs/EXP-018/budget_curves.json`.
- 2026-02-10: EXP-019 reran holdout generalization. PASS. Artifact: `runs/EXP-019/summary.json`.
- 2026-02-10: EXP-020 reran human-eval scale-up reproducibility run. PASS. Artifact: `runs/EXP-020/human_eval_report.json`.
- 2026-02-10: EXP-021 built scale oral dataset from v2 internal exports. PASS. Manifest: `runs/EXP-021/dataset/dataset_manifest.json`.
- 2026-02-10: EXP-022 ran scale oral main table + baselines + attacks. PASS. Artifacts: `runs/EXP-022/main_results.csv`, `runs/EXP-022/attacks/`, `runs/EXP-022/run_meta.json`.
- 2026-02-10: EXP-023 ran defense knob sweep tradeoff curve. PASS. Artifacts: `runs/EXP-023/tradeoff_curve.png`, `runs/EXP-023/tradeoff_curve.json`, `runs/EXP-023/run_meta.json`.
- 2026-02-10: EXP-024 ran human agreement report (kappa + alpha). PASS. Artifact: `runs/EXP-024/human_eval_report.json`.
- 2026-02-11: Reran plan-support experiments `EXP-001..020` (with `EXP-004` as expected-failure). PASS. Summary: `runs/PLAN-rerun/check.log`.
- 2026-02-11: EXP-025 ran scale (vNext) ablations on the non-toy dataset. PASS. Artifacts: `runs/EXP-025/ablation_results.csv`, `runs/EXP-025/attacks/`, `runs/EXP-025/run_meta.json`.
- 2026-02-11: EXP-026 ran scale cross-domain summary from EXP-022 per-run metrics. PASS. Artifacts: `runs/EXP-026/cross_domain_summary.json`, `runs/EXP-026/cross_domain_summary.md`.
- 2026-02-11: EXP-027 ran scale white-box defense (defended vs raw). PASS. Artifacts: `runs/EXP-027/summary.json`, `runs/EXP-027/defended_A.jsonl`, `runs/EXP-027/defended_B.jsonl`.
- 2026-02-11: EXP-028 ran scale stats (CI/p/d) from EXP-022 (+ defense snapshot from EXP-027). PASS. Artifacts: `runs/EXP-028/summary.json`, `runs/EXP-028/summary.md`.
- 2026-02-11: EXP-029 ran scale budget curves for sealed vs defended. PASS. Artifacts: `runs/EXP-029/budget_curves.json`, `runs/EXP-029/run_meta.json`.
- 2026-02-11: EXP-030 ran scale holdout generalization (temporal split). PASS. Artifacts: `runs/EXP-030/summary.json`, `runs/EXP-030/holdout_A_raw.jsonl`, `runs/EXP-030/holdout_B_raw.jsonl`.
- 2026-02-11: EXP-031 exported a public-safe scale dataset bundle (no codebooks) and smoke-reran scale main table on it (1 seed). Artifacts: `runs/EXP-031/public/public_dataset_manifest.json`, `runs/EXP-031/repro_main_table_smoke/main_results.csv`.
- 2026-02-11: EXP-032 ran LLM-backed term-recovery calibration (micro A/B + optional scale A/B) using `.env` API settings. PASS. Artifacts: `runs/EXP-032/summary.json`, `runs/EXP-032/summary.md`, `runs/EXP-032/run_meta.json`.
- 2026-02-11: EXP-033 derived a recommended release defense level from the scale tradeoff curve. PASS. Artifacts: `runs/EXP-033/recommended_config.json`, `runs/EXP-033/recommended_config.md`.
- 2026-02-11: EXP-034 implemented and smoke-ran contamination statistics (ConStat-style proxy). Artifacts: `runs/EXP-034/summary.json`, `runs/EXP-034/run_meta.json`.
- 2026-02-11: EXP-035 implemented and smoke-ran dynamic time-window evaluation (single-seed quick run). Artifacts: `runs/EXP-035/summary.json`, `runs/EXP-035/run_meta.json`.
- 2026-02-11: EXP-036 implemented and smoke-ran contamination tagging traceability diagnostics. Artifacts: `runs/EXP-036/summary.json`, `runs/EXP-036/run_meta.json`.
- 2026-02-11: EXP-037 implemented and smoke-ran extraction stress test (reduced budgets for smoke). Artifacts: `runs/EXP-037/summary.json`, `runs/EXP-037/run_meta.json`.
- 2026-02-11: EXP-038 implemented and smoke-ran judge-vs-human validation (heuristic judge baseline). Artifacts: `runs/EXP-038/summary.json`, `runs/EXP-038/run_meta.json`.
- 2026-02-11: EXP-034 full run PASS (`--n_boot 4000`). Metrics: contamination_score=0.0085 (CI95 [0.0028, 0.0142]); corrected_utility_gap=-0.0662. Logs/artifacts: `runs/EXP-034/full_stderr.log`, `runs/EXP-034/summary.json`, `runs/EXP-034/run_meta.json`.
- 2026-02-11: EXP-035 full run PASS (seeds 11/22/33). Metrics: avg_utility_retention=0.9998; trend_holds_all_windows=true. Logs/artifacts: `runs/EXP-035/full_stderr.log`, `runs/EXP-035/summary.json`, `runs/EXP-035/run_meta.json`.
- 2026-02-11: EXP-036 full run PASS (`--max_negatives 300`). Metrics: mean_traceable_coverage=0.9964; mean_false_positive_rate=0.0. Logs/artifacts: `runs/EXP-036/full_stderr.log`, `runs/EXP-036/summary.json`, `runs/EXP-036/run_meta.json`.
- 2026-02-11: EXP-037 full run PASS (budgets 32/64/128/256). Metrics: sealed AUC(top1)=1.0 vs defended AUC(top1)=0.0; max-budget defended-minus-sealed white-box top1=-1.0. Logs/artifacts: `runs/EXP-037/full_stderr.log`, `runs/EXP-037/summary.json`, `runs/EXP-037/run_meta.json`.
- 2026-02-11: EXP-038 full run PASS (`threshold=0.5`). Metrics: kappa=1.0; spearman=1.0; mae=0.0017; pass_rule=true. Logs/artifacts: `runs/EXP-038/full_stderr.log`, `runs/EXP-038/summary.json`, `runs/EXP-038/run_meta.json`.
- 2026-02-11: EXP-039 full run PASS (seeds 11/22/33). Metrics: spearman(raw,sealed)=1.0; metadata_only frontier utility=0.5626. Logs/artifacts: `runs/EXP-039/summary.json`, `runs/EXP-039/run_meta.json`.
- 2026-02-11: EXP-040 full run PASS (LLM proposer; micro + scale; views raw/sealed/structure_only/metadata_only). Metrics: micro sealed utility within 0.08 of raw (A/B) and mechanism_class drops to ≤0.10 for metadata_only/structure_only; scale sealed ≥ raw and metadata_only/structure_only mechanism_class=0.0. Logs/artifacts: `runs/EXP-040/summary.json`, `runs/EXP-040/run_meta.json`.
