{
  "seed": 42,
  "forward": {
    "convolution": "quark",
    "normalization": "prism",
    "a_term_1": "nexus",
    "author_a1": "J. Smith",
    "coauthor_a1": "R. Chen",
    "synth_conf": "AICONF",
    "gradient-based learning applied to document recognition": "ZetaNet",
    "residual": "vertex",
    "a_term_2": "helix",
    "author_a2": "M. Ivanova",
    "coauthor_a2": "K. Tanaka",
    "imagenet classification with deep convolutional neural networks": "OmegaArch",
    "transformer": "lattice",
    "a_term_3": "matrix",
    "author_a3": "S. Patel",
    "coauthor_a3": "L. Garcia",
    "very deep convolutional networks for large-scale image recognition": "KappaModel",
    "self-supervised": "tensor",
    "a_term_4": "vector",
    "author_a4": "A. Johansson",
    "coauthor_a4": "D. Kowalski",
    "network in network": "SigmaBlock",
    "contrastive": "kernel",
    "a_term_5": "quark_1",
    "author_a5": "W. Okafor",
    "coauthor_a5": "P. Dubois",
    "going deeper with convolutions": "PhiStack",
    "detection": "prism_1",
    "a_term_6": "nexus_1",
    "author_a6": "J. Smith_1",
    "coauthor_a6": "R. Chen_1",
    "batch normalization: accelerating deep network training": "ThetaCore",
    "segmentation": "vertex_1",
    "a_term_7": "helix_1",
    "author_a7": "M. Ivanova_1",
    "coauthor_a7": "K. Tanaka_1",
    "deep residual learning for image recognition": "LambdaUnit",
    "distillation": "lattice_1",
    "a_term_8": "matrix_1",
    "author_a8": "S. Patel_1",
    "coauthor_a8": "L. Garcia_1",
    "densely connected convolutional networks": "DeltaFrame",
    "scaling": "tensor_1",
    "a_term_9": "vector_1",
    "author_a9": "A. Johansson_1",
    "coauthor_a9": "D. Kowalski_1",
    "squeeze-and-excitation networks": "EpsilonNode",
    "a_term_10": "kernel_1",
    "author_a10": "W. Okafor_1",
    "coauthor_a10": "P. Dubois_1",
    "mobilenets: efficient convolutional neural networks for mobile vision applications": "RhoNet",
    "a_term_11": "quark_2",
    "author_a11": "J. Smith_2",
    "coauthor_a11": "R. Chen_2",
    "neural architecture search with reinforcement learning": "ZetaNet_1",
    "a_term_12": "prism_2",
    "author_a12": "M. Ivanova_2",
    "coauthor_a12": "K. Tanaka_2",
    "efficientnet: rethinking model scaling for convolutional neural networks": "OmegaArch_1",
    "a_term_13": "nexus_2",
    "author_a13": "S. Patel_2",
    "coauthor_a13": "L. Garcia_2",
    "an image is worth 16x16 words: transformers for image recognition at scale": "KappaModel_1",
    "a_term_14": "vertex_2",
    "author_a14": "A. Johansson_2",
    "coauthor_a14": "D. Kowalski_2",
    "training data-efficient image transformers & distillation through attention": "SigmaBlock_1",
    "a_term_15": "helix_2",
    "author_a15": "W. Okafor_2",
    "coauthor_a15": "P. Dubois_2",
    "swin transformer: hierarchical vision transformer using shifted windows": "PhiStack_1",
    "a_term_16": "lattice_2",
    "author_a16": "J. Smith_3",
    "coauthor_a16": "R. Chen_3",
    "masked autoencoders are scalable vision learners": "ThetaCore_1",
    "a_term_17": "matrix_2",
    "author_a17": "M. Ivanova_3",
    "coauthor_a17": "K. Tanaka_3",
    "learning transferable visual models from natural language supervision": "LambdaUnit_1",
    "a_term_18": "tensor_2",
    "author_a18": "S. Patel_3",
    "coauthor_a18": "L. Garcia_3",
    "a convnet for the 2020s": "DeltaFrame_1",
    "a_term_19": "vector_2",
    "author_a19": "A. Johansson_3",
    "coauthor_a19": "D. Kowalski_3",
    "scaling vision transformers to 22 billion parameters": "EpsilonNode_1",
    "a_term_20": "kernel_2",
    "author_a20": "W. Okafor_3",
    "coauthor_a20": "P. Dubois_3",
    "segment anything": "RhoNet_1"
  },
  "category_counters": {
    "keyword": 30,
    "author": 40,
    "venue": 1,
    "model": 20
  }
}